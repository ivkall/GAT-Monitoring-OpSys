{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 18:03:33.419943: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-26 18:03:33.520897: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-26 18:03:33.522080: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-26 18:03:34.458009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DataPoint:\n",
    "    def __init__(self, features, adjacency_matrix):\n",
    "        self.features = features\n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "\n",
    "# Load the data\n",
    "with open(\"data2_100.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.linear(x).float()  # Ensuring the output is float\n",
    "        x = torch.matmul(adj.float(), x)  # Ensuring both operands are float\n",
    "        return x\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(input_dim, hidden_dim)\n",
    "        self.gc2 = GraphConvolution(hidden_dim, hidden_dim)  # Second layer\n",
    "        self.gc3 = GraphConvolution(hidden_dim, hidden_dim)  # Second layer\n",
    "        self.gc4 = GraphConvolution(hidden_dim, hidden_dim)  # Fourth layer\n",
    "        self.gc5 = GraphConvolution(hidden_dim, output_dim)  # Output layer with output_dim neurons\n",
    "\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "    \n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.relu(self.gc2(x, adj))\n",
    "        x = F.relu(self.gc3(x, adj))\n",
    "        x = F.relu(self.gc4(x, adj))\n",
    "        x = self.gc5(x, adj)  # No ReLU here before the final softmax\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Example usage\n",
    "num_nodes = len(data[0].features)  # Number of nodes in the graph\n",
    "num_features = 4  # Number of features per node\n",
    "hidden_channels = 8  # Hidden layer size\n",
    "output_channels = 8 # Number of output channels for the final features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the GCN model\n",
    "model = GCN(num_features, hidden_channels, output_channels)\n",
    "\n",
    "# Process each data point through the GCN and collect transformed features\n",
    "transformed_features = []\n",
    "for data_point in data:\n",
    "    adj_matrix = torch.tensor(data_point.adjacency_matrix, dtype=torch.float)\n",
    "    features = torch.tensor(data_point.features, dtype=torch.float)\n",
    "    adj_matrix = adj_matrix.cpu()\n",
    "    features = features.cpu()\n",
    "    \n",
    "    # Forward pass through GCN\n",
    "    output = model(features, adj_matrix).detach()  # Detach the output from the graph\n",
    "    transformed_features.append(output)\n",
    "\n",
    "# Concatenate all the outputs to form a single dataset\n",
    "all_transformed_features = torch.cat(transformed_features, dim=0).numpy()\n",
    "\n",
    "# Now all_transformed_features is ready for the autoencoder\n",
    "all_transformed_features_numpy = all_transformed_features\n",
    "\n",
    "# Normalize the data\n",
    "mean = np.mean(all_transformed_features_numpy, axis=0)\n",
    "std = np.std(all_transformed_features_numpy, axis=0)\n",
    "std[std == 0] = 1  # Avoid division by zero\n",
    "normalized_training_data_numpy = (all_transformed_features_numpy - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print(normalized_training_data_numpy)\n",
    "# Extract features from each DataPoint object and store in x and y lists\n",
    "x = normalized_training_data_numpy[:,0]\n",
    "y = normalized_training_data_numpy[:,1]\n",
    "%matplotlib notebook\n",
    "# Plot the scatter plot\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Scatter Plot of Data Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4627 - val_loss: 0.4153\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4593 - val_loss: 0.4137\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4569 - val_loss: 0.4120\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4556 - val_loss: 0.4100\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4537 - val_loss: 0.4076\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4513 - val_loss: 0.4046\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4483 - val_loss: 0.4010\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4449 - val_loss: 0.3969\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4409 - val_loss: 0.3924\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4365 - val_loss: 0.3872\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4316 - val_loss: 0.3816\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4262 - val_loss: 0.3755\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4202 - val_loss: 0.3687\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4136 - val_loss: 0.3613\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4064 - val_loss: 0.3534\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3986 - val_loss: 0.3448\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3903 - val_loss: 0.3357\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3814 - val_loss: 0.3261\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3720 - val_loss: 0.3160\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3621 - val_loss: 0.3056\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3518 - val_loss: 0.2949\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3412 - val_loss: 0.2839\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3302 - val_loss: 0.2728\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3190 - val_loss: 0.2615\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3076 - val_loss: 0.2502\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2961 - val_loss: 0.2389\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2844 - val_loss: 0.2275\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2727 - val_loss: 0.2163\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2610 - val_loss: 0.2052\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2492 - val_loss: 0.1942\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2376 - val_loss: 0.1835\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2260 - val_loss: 0.1731\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2146 - val_loss: 0.1630\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2033 - val_loss: 0.1532\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1923 - val_loss: 0.1439\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1815 - val_loss: 0.1349\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1710 - val_loss: 0.1264\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1608 - val_loss: 0.1184\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1510 - val_loss: 0.1108\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1415 - val_loss: 0.1038\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1324 - val_loss: 0.0972\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1237 - val_loss: 0.0911\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1153 - val_loss: 0.0855\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1074 - val_loss: 0.0803\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1000 - val_loss: 0.0757\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0930 - val_loss: 0.0715\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0864 - val_loss: 0.0677\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0803 - val_loss: 0.0643\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0747 - val_loss: 0.0613\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0694 - val_loss: 0.0586\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0646 - val_loss: 0.0562\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0602 - val_loss: 0.0540\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0560 - val_loss: 0.0520\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0522 - val_loss: 0.0501\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0487 - val_loss: 0.0483\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0455 - val_loss: 0.0466\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0425 - val_loss: 0.0451\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0399 - val_loss: 0.0437\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0375 - val_loss: 0.0424\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0353 - val_loss: 0.0412\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0334 - val_loss: 0.0401\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0317 - val_loss: 0.0392\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0302 - val_loss: 0.0384\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0290 - val_loss: 0.0378\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0278 - val_loss: 0.0373\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0268 - val_loss: 0.0368\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0259 - val_loss: 0.0364\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0251 - val_loss: 0.0361\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0244 - val_loss: 0.0356\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0237 - val_loss: 0.0352\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0231 - val_loss: 0.0347\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0225 - val_loss: 0.0344\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0220 - val_loss: 0.0341\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0215 - val_loss: 0.0338\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0210 - val_loss: 0.0335\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0206 - val_loss: 0.0332\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0201 - val_loss: 0.0328\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0197 - val_loss: 0.0324\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0194 - val_loss: 0.0321\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0190 - val_loss: 0.0318\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0187 - val_loss: 0.0316\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0184 - val_loss: 0.0314\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0182 - val_loss: 0.0310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0179 - val_loss: 0.0307\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0176 - val_loss: 0.0304\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0174 - val_loss: 0.0301\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0171 - val_loss: 0.0298\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0169 - val_loss: 0.0295\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0166 - val_loss: 0.0292\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0164 - val_loss: 0.0289\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0161 - val_loss: 0.0285\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0159 - val_loss: 0.0281\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0157 - val_loss: 0.0278\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0154 - val_loss: 0.0275\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0152 - val_loss: 0.0271\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0150 - val_loss: 0.0268\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0148 - val_loss: 0.0264\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0146 - val_loss: 0.0261\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0145 - val_loss: 0.0257\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0143 - val_loss: 0.0254\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0141 - val_loss: 0.0251\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0139 - val_loss: 0.0248\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0138 - val_loss: 0.0245\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0136 - val_loss: 0.0242\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0135 - val_loss: 0.0239\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0134 - val_loss: 0.0236\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0132 - val_loss: 0.0233\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0131 - val_loss: 0.0231\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0130 - val_loss: 0.0228\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0129 - val_loss: 0.0225\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0127 - val_loss: 0.0223\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0126 - val_loss: 0.0221\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0125 - val_loss: 0.0219\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0124 - val_loss: 0.0216\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0123 - val_loss: 0.0214\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0122 - val_loss: 0.0212\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0121 - val_loss: 0.0210\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0120 - val_loss: 0.0208\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0118 - val_loss: 0.0206\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0117 - val_loss: 0.0204\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0116 - val_loss: 0.0202\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0115 - val_loss: 0.0200\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0114 - val_loss: 0.0197\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0113 - val_loss: 0.0195\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0112 - val_loss: 0.0193\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0111 - val_loss: 0.0191\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0110 - val_loss: 0.0189\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0109 - val_loss: 0.0187\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0108 - val_loss: 0.0184\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0107 - val_loss: 0.0182\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0106 - val_loss: 0.0180\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0105 - val_loss: 0.0178\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0176\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0103 - val_loss: 0.0174\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0102 - val_loss: 0.0172\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0101 - val_loss: 0.0170\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0100 - val_loss: 0.0168\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0099 - val_loss: 0.0165\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0098 - val_loss: 0.0163\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0097 - val_loss: 0.0161\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0097 - val_loss: 0.0159\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0096 - val_loss: 0.0157\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0095 - val_loss: 0.0155\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0094 - val_loss: 0.0153\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0093 - val_loss: 0.0151\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0092 - val_loss: 0.0149\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0091 - val_loss: 0.0147\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0091 - val_loss: 0.0145\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0090 - val_loss: 0.0143\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0089 - val_loss: 0.0141\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0088 - val_loss: 0.0140\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0087 - val_loss: 0.0138\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0087 - val_loss: 0.0136\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0086 - val_loss: 0.0134\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0085 - val_loss: 0.0133\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0084 - val_loss: 0.0131\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0084 - val_loss: 0.0129\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0083 - val_loss: 0.0127\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0082 - val_loss: 0.0126\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0082 - val_loss: 0.0124\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0081 - val_loss: 0.0122\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0080 - val_loss: 0.0121\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0079 - val_loss: 0.0119\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0079 - val_loss: 0.0118\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0078 - val_loss: 0.0116\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0077 - val_loss: 0.0114\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0077 - val_loss: 0.0113\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0076 - val_loss: 0.0111\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0076 - val_loss: 0.0110\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0075 - val_loss: 0.0109\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0074 - val_loss: 0.0107\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0074 - val_loss: 0.0106\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0072 - val_loss: 0.0100\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0071 - val_loss: 0.0099\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0070 - val_loss: 0.0098\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0070 - val_loss: 0.0096\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0069 - val_loss: 0.0095\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0068 - val_loss: 0.0093\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0068 - val_loss: 0.0091\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0067 - val_loss: 0.0090\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0066 - val_loss: 0.0087\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0064 - val_loss: 0.0082\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0056 - val_loss: 0.0068\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - val_loss: 0.0065\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0055 - val_loss: 0.0065\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 248/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Comparing original and reconstructed values for random data points:\n",
      "\n",
      "Data Point 1 (Index 9):\n",
      "[(-0.009453297, -0.037996072), (-0.16571331, -0.14115842), (-0.06646824, -0.04083491), (0.15322351, 0.16689831), (-0.27944756, -0.24826013), (0.57857513, 0.5702189), (0.5040031, 0.51274085), (-0.095761776, -0.09522376), (0.48804855, 0.32597142), (0.3532927, 0.31883937)]\n",
      "\n",
      "Data Point 2 (Index 14):\n",
      "[(-0.1770401, -0.148355), (0.032193184, -0.010741518), (0.11327553, 0.07126077), (0.26348495, 0.26103535), (-0.03843689, -0.08804207), (0.39201736, 0.4357788), (0.6003381, 0.5928054), (-0.20797491, -0.15597498), (0.10575867, 0.35938105), (0.015130997, 0.17617917)]\n",
      "\n",
      "Data Point 3 (Index 18):\n",
      "[(-0.16148376, -0.1825792), (0.003209114, 0.02418711), (0.09510422, 0.10835986), (0.2792368, 0.3036902), (-0.06843376, -0.06401541), (0.4243641, 0.42458063), (0.6251437, 0.6445953), (-0.21288276, -0.17319268), (0.4113388, 0.38427946), (0.23742795, 0.15394223)]\n",
      "\n",
      "Data Point 4 (Index 7):\n",
      "[(-0.045572758, -0.04282789), (-0.11532211, -0.1299892), (-0.033880234, -0.035872642), (0.16478157, 0.16541028), (-0.21971798, -0.23165207), (0.5353508, 0.5487221), (0.51755935, 0.49788052), (0.018000841, -0.09629392), (0.33654404, 0.31600463), (0.23908162, 0.3029594)]\n",
      "\n",
      "Data Point 5 (Index 15):\n",
      "[(0.007955074, -0.015993938), (-0.1941576, -0.1773554), (-0.0919857, -0.07586395), (0.13826323, 0.1418228), (-0.31329536, -0.3065719), (0.6101608, 0.6050675), (0.4846856, 0.47104374), (-0.056414843, -0.081686854), (0.4874382, 0.30542985), (0.37176228, 0.36870283)]\n",
      "Training Loss:  0.004429110791534185\n",
      "Validation Loss:  0.005367032252252102\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the Graph Convolutional Layer\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.linear(x)\n",
    "        x = torch.matmul(adj, x)\n",
    "        return x\n",
    "\n",
    "# Define the GCN Model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(input_dim, hidden_dim1)\n",
    "        # Additional intermediate layer\n",
    "        self.gc2 = GraphConvolution(hidden_dim1, hidden_dim2)\n",
    "        self.gc3 = GraphConvolution(hidden_dim2, output_dim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.relu(self.gc2(x, adj))  # Pass through the second (new) layer with ReLU\n",
    "        x = self.gc3(x, adj)  # Output layer does not have ReLU if it's the final output\n",
    "        return x\n",
    "\n",
    "# Load and prepare the data\n",
    "class DataPoint:\n",
    "    def __init__(self, features, adjacency_matrix):\n",
    "        self.features = features\n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "\n",
    "with open(\"data2_100.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Initialize a GCN model\n",
    "input_dim = len(data[0].features[0])\n",
    "hidden_dim = 32  # You can tune this\n",
    "hidden_dim2 = 16\n",
    "output_dim = 12  # You can tune this, should match autoencoder input\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gcn_model = GCN(input_dim, hidden_dim,hidden_dim2, output_dim).to(device)\n",
    "\n",
    "# Assuming the adjacency matrices are the same for all data points and stored in data[0].adjacency_matrix\n",
    "adj_matrix = torch.tensor(data[0].adjacency_matrix, dtype=torch.float).to(device)\n",
    "\n",
    "# Process data through GCN\n",
    "gcn_transformed_features = []\n",
    "for data_point in data:\n",
    "    features_tensor = torch.tensor(data_point.features, dtype=torch.float).to(device)\n",
    "    transformed_features = gcn_model(features_tensor, adj_matrix).detach().cpu().numpy()\n",
    "    gcn_transformed_features.append(transformed_features.flatten())\n",
    "\n",
    "# Convert list to NumPy array\n",
    "gcn_transformed_features = np.array(gcn_transformed_features)\n",
    "\n",
    "# Now we proceed with the autoencoder using the transformed features\n",
    "input_dim = gcn_transformed_features.shape[1]\n",
    "encoding_dim = 12  # This should match the GCN's output_dim\n",
    "\n",
    "input_img = tf.keras.Input(shape=(input_dim,))\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "encoded = layers.Dense(int(encoding_dim * 3/4), activation='relu')(encoded)\n",
    "encoded = layers.Dense(int(encoding_dim / 2), activation='relu')(encoded)\n",
    "decoded = layers.Dense(int(encoding_dim * 3/4), activation='relu')(encoded)\n",
    "decoded = layers.Dense(encoding_dim, activation='relu')(decoded)\n",
    "decoded = layers.Dense(input_dim, activation='tanh')(decoded)\n",
    "\n",
    "autoencoder = models.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Normalize the GCN transformed data and split it\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "gcn_transformed_features_scaled = scaler.fit_transform(gcn_transformed_features)\n",
    "train_data, val_data = train_test_split(gcn_transformed_features_scaled, test_size=0.2)\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoencoder.fit(train_data, train_data,\n",
    "                          epochs=300,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(val_data, val_data))\n",
    "\n",
    "# Evaluate the model and visualize the reconstruction quality\n",
    "reconstructed_data = autoencoder.predict(val_data)\n",
    "\n",
    "# Select random samples to display their original and reconstructed values\n",
    "num_samples_to_display = 5\n",
    "indices = np.random.choice(range(len(val_data)), num_samples_to_display)\n",
    "\n",
    "print(\"Comparing original and reconstructed values for random data points:\")\n",
    "for i, index in enumerate(indices):\n",
    "    print(f\"\\nData Point {i + 1} (Index {index}):\")\n",
    "    \n",
    "    print(list(zip(val_data[index][:10], reconstructed_data[index][:10])))\n",
    "\n",
    "# Visualizing the reconstruction for selected samples\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "print(\"Training Loss: \", train_loss[-1])\n",
    "print(\"Validation Loss: \", val_loss[-1])\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
